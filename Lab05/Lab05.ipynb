{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Nguyễn Hữu Quyến - 19522113\n",
        "\n",
        "Lab 5\n",
        "\n"
      ],
      "metadata": {
        "id": "VzVdnYoLgzRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab_Notebooks/Data_Mining/Thuc_hanh/job-market.csv\")\n",
        "\n",
        "accounting_jobs = df[df['Classification'] == 'Accounting']\n",
        "\n",
        "subsector_counts = accounting_jobs['SubClassification'].value_counts()\n",
        "\n",
        "fig = px.bar(x=subsector_counts.index, y=subsector_counts.values, labels={'x':'Sub-sector', 'y':'Count'}, color=subsector_counts.index)\n",
        "fig.update_layout(title='Accounting')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Cgk3Bf47xodt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert the 'Date' column to datetime format\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Filter the data for the month of October 2018\n",
        "df = df[(df['Date'] >= '2018-10-01') & (df['Date'] <= '2018-10-31')]\n",
        "\n",
        "# Group the data by day and count the job postings\n",
        "job_postings_by_day = df.groupby(pd.Grouper(key='Date', freq='D'))['Title'].count()\n",
        "\n",
        "# Create a line graph of the job postings by day using Matplotlib\n",
        "plt.plot(job_postings_by_day.index, job_postings_by_day.values)\n",
        "plt.xticks(job_postings_by_day.index, [d.strftime('%d.%b') for d in job_postings_by_day.index], rotation=45)\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Job Postings by Date')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EMwy2mvqx0DR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Section 2: Moving Beyond Static Visualizations"
      ],
      "metadata": {
        "id": "SV_Twsjix7R9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "questions_per_library = pd.read_csv(\n",
        "'/content/drive/MyDrive/Colab_Notebooks/Data_Mining/Thuc_hanh/data/data/stackoverflow.zip', parse_dates=True, index_col='creation_date'\n",
        ").loc[:, 'pandas': 'bokeh'].resample ('1M').sum().cumsum().reindex( pd.date_range('2008-08', '2021-10', freq= 'M')\n",
        ").fillna(0)\n",
        "questions_per_library.tail()"
      ],
      "metadata": {
        "id": "nGx79tSNx8PB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.animation import FuncAnimation"
      ],
      "metadata": {
        "id": "Ukj4d0pLyOM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "from matplotlib import ticker\n",
        "def bar_plot(data):\n",
        "  fig, ax = plt.subplots (figsize=(8, 6))\n",
        "  sort_order = data.last('1M').squeeze().sort_values().index \n",
        "  bars = [\n",
        "    bar.set_label(label) for label, bar in\n",
        "    zip(sort_order, ax.barh (sort_order, [0] * data.shape[1]))\n",
        "]\n",
        "\n",
        "  ax.set_xlabel('total questions', fontweight='bold')\n",
        "  ax.set_xlim(0, 250_000)\n",
        "  ax.xaxis.set_major_formatter (ticker. EngFormatter()) \n",
        "  ax.xaxis.set_tick_params (labelsize=12) \n",
        "  ax.yaxis.set_tick_params (labelsize=12)\n",
        "  for spine in ['top', 'right']:\n",
        "    ax.spines[spine].set_visible (False)\n",
        "  fig.tight_layout()\n",
        "  return fig, ax"
      ],
      "metadata": {
        "id": "hiSypqJByPsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%config InlineBackend.figure_formats = ['svg']\n",
        "%matplotlib inline\n",
        "bar_plot(questions_per_library)"
      ],
      "metadata": {
        "id": "MoLZc8bCyTRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_plot_text(ax):\n",
        "  annotations = [\n",
        "    ax.annotate(\n",
        "      '', xy=(0, bar.get_y() + bar.get_height()/2), \n",
        "      ha='left', va='center'\n",
        "    ) for bar in ax.patches\n",
        "]\n",
        "\n",
        "  time_text = ax.text(\n",
        "      0.9, 0.1,'', transform=ax.transAxes,\n",
        "      fontsize=15, ha='center', va='center'\n",
        "  )\n",
        "\n",
        "  return annotations, time_text"
      ],
      "metadata": {
        "id": "YO2kEPQQyay-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update (frame,*, ax, df, annotations, time_text): \n",
        "  data=df.loc[frame, :]\n",
        "# update bars\n",
        "  for rect, text in zip(ax.patches, annotations):\n",
        "    col = rect.get_label()\n",
        "    if data[col]:\n",
        "      rect.set_width (data[col])\n",
        "      text.set_x(data[col])\n",
        "      text.set_text(f' {data[col]:,.0f}')\n",
        "  #update time\n",
        "  time_text.set_text(frame.strftime('\\b\\n\\Y'))"
      ],
      "metadata": {
        "id": "dFUHhUcYycfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "def bar_plot_init(questions_per_library): \n",
        "  fig, ax = bar_plot (questions_per_library)\n",
        "  annotations, time_text = generate_plot_text(ax)\n",
        "  \n",
        "  bar_plot_update = partial(\n",
        "\n",
        "    update, ax=ax, df=questions_per_library, \n",
        "    annotations=annotations, time_text=time_text\n",
        "  )\n",
        "\n",
        "  return fig, bar_plot_update"
      ],
      "metadata": {
        "id": "JrlKAB0tygS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, update_func = bar_plot_init(questions_per_library)\n",
        "ani = FuncAnimation(\n",
        "  fig, update_func, frames=questions_per_library.index, repeat=False\n",
        ")\n",
        "ani.save(\n",
        "    '../media/stackoverflow_questions.mp4', \n",
        "    writer='ffmpeg', fps=10, bitrate=100, dpi=300\n",
        ")\n",
        "\n",
        "plt.close()\n"
      ],
      "metadata": {
        "id": "_ZKfQmMVykFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import display\n",
        "display.Video(\n",
        "'../media/stackoverflow_questions.mp4', width=600, height=400, embed=True, html_attributes='controls muted autoplay'\n",
        ")"
      ],
      "metadata": {
        "id": "fsoKhmuly2we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Animating distributions over time"
      ],
      "metadata": {
        "id": "iBsuBvM_zAdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subway = pd.read_csv(\n",
        "    '/content/drive/MyDrive/Colab_Notebooks/Data_Mining/Thuc_hanh/data/data/NYC_subway_daily.csv', parse_dates=['Datetime'],\n",
        "    index_col=['Borough', 'Datetime']\n",
        ")\n",
        "subway_daily= subway.unstack(0)\n",
        "subway_daily.head()"
      ],
      "metadata": {
        "id": "VT3Ep50dzA9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "manhattan_entries = subway_daily['Entries']['M']"
      ],
      "metadata": {
        "id": "zdUJmdH2zItN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "count_per_bin, bin_ranges = np.histogram(manhattan_entries,bins=30)"
      ],
      "metadata": {
        "id": "Q2ZJmL4wzL-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def subway_histogram(data,bins, date_range):\n",
        "    _,bin_ranges = np.histogram(data, bins=bins)\n",
        "    weekday_mask= data.index.weekday <5\n",
        "    configs = [\n",
        "    {'label':'Weekend','mask': ~weekday_mask, 'ymax': 60},\n",
        "    {'label': 'Weekday', 'mask':weekday_mask, 'ymax': 120}\n",
        "    ]\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(8, 4), sharex=True)\n",
        "    for ax, config in zip (axes, configs):\n",
        "\n",
        "      _, _,config['hist'] = ax.hist(\n",
        "      data[config['mask']].loc[date_range], bin_ranges, ec='black'\n",
        "      )\n",
        "      ax.xaxis.set_major_formatter (ticker. EngFormatter())\n",
        "      ax.set(\n",
        "        xlim=(0, None), ylim=(0, config['ymax']), \n",
        "        xlabel=f' {config[\"label\"]} Entries'\n",
        "      )\n",
        "\n",
        "      for spine in ['top', 'right']:\n",
        "        ax.spines [spine].set_visible (False)\n",
        "        axes[0].set_ylabel('Frequency')\n",
        "        fig.suptitle('Histogram of Daily Subway Entries in Manhattan')\n",
        "        fig.tight_layout()\n",
        "    return fig, axes, bin_ranges, configs"
      ],
      "metadata": {
        "id": "fXNyFS3zzO7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = subway_histogram(manhattan_entries, bins=30, date_range='2017')"
      ],
      "metadata": {
        "id": "1_g68L_MzSvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_time_text(ax):\n",
        "  time_text = ax.text(\n",
        "      0.15, 0.9, '', transform=ax.transAxes,\n",
        "      fontsize=15, ha='center', va='center'\n",
        "  )\n",
        "  return time_text"
      ],
      "metadata": {
        "id": "cmairBBUzWj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update(frame, *, data, configs, time_text, bin_ranges):\n",
        "   artists = []\n",
        "\n",
        "   time=frame.strftime('%b\\n%Y')\n",
        "   if time != time_text.get_text():\n",
        "     time_text.set_text(time)\n",
        "     artists.append(time_text)\n",
        "\n",
        "   for config in configs:\n",
        "     time_frame_mask = \\\n",
        "        (data.index > frame -pd.Timedelta(days=365)) & (data.index <= frame)\n",
        "     counts, _= np.histogram(\n",
        "         data[time_frame_mask & config['mask']],\n",
        "         bin_ranges\n",
        "     )\n",
        "     for count, rect in zip(counts, config['hist'].patches):\n",
        "       if count != rect.get_height():\n",
        "            rect.set_height(count)\n",
        "            artists.append(rect)\n",
        "\n",
        "   return artists"
      ],
      "metadata": {
        "id": "4G7wu_6fzZU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def histogram_init(data, bins, initial_date_range):\n",
        "  fig, axes, bin_ranges, configs = subway_histogram(data, bins, initial_date_range)\n",
        "\n",
        "  update_func= partial(\n",
        "      update, data=data, configs=configs,\n",
        "      time_text=add_time_text(axes[0]),\n",
        "      bin_ranges=bin_ranges\n",
        "  )\n",
        "\n",
        "  return fig, update_func"
      ],
      "metadata": {
        "id": "St3Q-QtdzchW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, update_func = histogram_init(\n",
        "  manhattan_entries, bins=30, initial_date_range=slice('2017', '2019-07')\n",
        "\n",
        ")\n",
        "ani = FuncAnimation(\n",
        "  fig, update_func, frames=manhattan_entries['2019-08':'2021'].index,\n",
        "  repeat=False, blit=True\n",
        "\n",
        ")\n",
        "ani.save(\n",
        "    '../media/subway_entries_subplots.mp4', \n",
        "    writer='ffmpeg', fps=30, bitrate=500, dpi=300\n",
        ")\n",
        "\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "otyfaBMFzfNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import display\n",
        "display.Video(\n",
        "'../media/subway_entries_subplots.mp4', width=600, height=400, embed=True, html_attributes='controls muted autoplay'\n",
        ")"
      ],
      "metadata": {
        "id": "PbnWryyQ0jaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Animating geospatial data with HoloViz"
      ],
      "metadata": {
        "id": "RYS24MAK0xBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geopandas"
      ],
      "metadata": {
        "id": "BWI1agL41ltj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "\n",
        "earthquakes = gpd.read_file('/content/drive/MyDrive/Colab_Notebooks/Data_Mining/Thuc_hanh/data/data/earthquakes.geojson').assign(\n",
        "    time = lambda x: pd.to_datetime(x.time, unit='ms'),\n",
        "    month = lambda x: x.time.dt.month\n",
        ")[['geometry', 'mag', 'time', 'month']]\n",
        "\n",
        "earthquakes.shape"
      ],
      "metadata": {
        "id": "bZx3D45X0qV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earthquakes.head()"
      ],
      "metadata": {
        "id": "Y7w67N5h2EGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geoviews"
      ],
      "metadata": {
        "id": "qMuWMky42cy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geoviews as gv\n",
        "import geoviews.feature as gf\n",
        "import holoviews as hv\n",
        "\n",
        "gv.extension('matplotlib')"
      ],
      "metadata": {
        "id": "sd_ogI4h2JuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import calendar\n",
        "\n",
        "def plot_earthquakes(data, month_num):\n",
        "  points = gv.Points(\n",
        "      data.query(f'month == {month_num}'),\n",
        "      kdims = ['longitude', 'latitude'],\n",
        "      vdims = ['mag']\n",
        "  ).redim.range(mag = (-2, 10), latitude = (-90, 90))\n",
        "\n",
        "  overlay = gf.land * gf.coastline * gf.borders * points\n",
        "\n",
        "  return overlay.opts(\n",
        "      gv.opts.Points(color = 'mag', cmap = 'fire_r', colorbar = True, alpha = 0.75),\n",
        "      gv.opts.Overlay(\n",
        "          global_extent = False, title = f'{calendar.month_name[month_num]}', fontscale = 2\n",
        "      )\n",
        "  )"
      ],
      "metadata": {
        "id": "kRrMDaDN2sXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_earthquakes(earthquakes, 1).opts(\n",
        "    fig_inches=(6, 3), aspect=2, fig_size=250, fig_bounds=(0.07, 0.05, 0.87, 0.95)\n",
        ")"
      ],
      "metadata": {
        "id": "GDZhCVrz3Nj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames = {\n",
        "    month_num: plot_earthquakes(earthquakes, month_num)\n",
        "    for month_num in range(1, 13)\n",
        "}\n",
        "holomap = hv.HoloMap(frames)"
      ],
      "metadata": {
        "id": "HusmOiG14J6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hv.output(\n",
        "    holomap.opts(\n",
        "        fig_inches=(6, 3), aspect=2, fig_size=250,\n",
        "        fig_bounds=(0.07, 0.05, 0.87, 0.95)\n",
        "    ), holomap='gif', fps=5\n",
        ")"
      ],
      "metadata": {
        "id": "tGakJgqF5D8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hv.save(\n",
        "    holomap.opts(\n",
        "        fig_inches=(6, 3), aspect=2, fig_size=250,\n",
        "        fig_bounds=(0.07, 0.05, 0.87, 0.95)\n",
        "    ), 'earthquakes.gif', fps=5\n",
        ")"
      ],
      "metadata": {
        "id": "KIh045ww5H0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Section 3: Building Interactive Visualizations for Data Exploration"
      ],
      "metadata": {
        "id": "fbLkcn5t5O6u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Read in and prepare the data."
      ],
      "metadata": {
        "id": "EEvQGKon5QF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "\n",
        "earthquakes = gpd.read_file('/content/drive/MyDrive/Colab_Notebooks/Data_Mining/Thuc_hanh/data/data/earthquakes.geojson').assign(\n",
        "    time=lambda x: pd.to_datetime(x.time, unit='ms'),\n",
        "    month=lambda x: x.time.dt.month\n",
        ").dropna()\n",
        "\n",
        "earthquakes.head()"
      ],
      "metadata": {
        "id": "i-4SSOKM5PfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Import the required libraries and set up the Bokeh backend."
      ],
      "metadata": {
        "id": "Y9c0ycjZ5rg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from cartopy import crs\n",
        "import geoviews as gv\n",
        "import geoviews.feature as gf\n",
        "\n",
        "gv.extension('bokeh')"
      ],
      "metadata": {
        "id": "cP7wNxH35pFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Create an overlay with tooltips and a slider."
      ],
      "metadata": {
        "id": "RN961ITR513C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "points = gv.Points(\n",
        "    earthquakes,\n",
        "    kdims=['longitude', 'latitude'],\n",
        "    vdims=['month', 'place', 'tsunami', 'mag', 'magType']\n",
        ")\n",
        "\n",
        "# set colorbar limits for magnitude and axis limits\n",
        "points = points.redim.range(\n",
        "    mag=(-2, 10), longitude=(-180, 180), latitude=(-90, 90)\n",
        ")"
      ],
      "metadata": {
        "id": "ZYdVgOFu5yYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overlay = gf.land * gf.coastline * gf.borders * points.groupby('month')"
      ],
      "metadata": {
        "id": "q0dalSa-56Bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interactive_map = overlay.opts(\n",
        "    gv.opts.Feature(projection=crs.PlateCarree()),\n",
        "    gv.opts.Overlay(width=700, height=450),\n",
        "    gv.opts.Points(color='mag', cmap='fire_r', colorbar=True, tools=['hover'])\n",
        ")"
      ],
      "metadata": {
        "id": "NJnITWHY589e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Render the visualization."
      ],
      "metadata": {
        "id": "LpwBEVU66C9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import panel as pn\n",
        "\n",
        "earthquake_viz = pn.panel(interactive_map, widget_location='bottom')"
      ],
      "metadata": {
        "id": "7JH4iWna6Aao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earthquake_viz.embed()"
      ],
      "metadata": {
        "id": "l-moiU4n6IaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linking plots\n"
      ],
      "metadata": {
        "id": "YZjnFF0A8AAa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Isolate the January earthquake data and prepare it for plotting."
      ],
      "metadata": {
        "id": "G5Pw0khX8A_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "january_earthquakes = earthquakes.query('month == 1').assign(\n",
        "    longitude=lambda x: x.geometry.x,\n",
        "    latitude=lambda x: x.geometry.y\n",
        ").drop(columns=['month', 'geometry'])"
      ],
      "metadata": {
        "id": "UYXqs21_6ALj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Enable the use of hvPlot for interactive plotting with pandas."
      ],
      "metadata": {
        "id": "DOg2YYnO8phP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install panel hvplot"
      ],
      "metadata": {
        "id": "U8uaTWnN9Sgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import hvplot.pandas\n"
      ],
      "metadata": {
        "id": "4Zr88Au_8o7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Build a layout composed of an interactive map and a table with hvPlot."
      ],
      "metadata": {
        "id": "BIsydkeG9cZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "geo = january_earthquakes.hvplot(\n",
        "    x='longitude', y='latitude', kind='points',\n",
        "    color='mag', cmap='fire_r', clim=(-2, 10),\n",
        "    tiles='CartoLight', geo=True, global_extent=True,\n",
        "    xlabel='Longitude', ylabel='Latitude', title='January 2020 Earthquakes',\n",
        "    frame_height=450\n",
        ")"
      ],
      "metadata": {
        "id": "3iI36M4D9dLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table = january_earthquakes.sort_values(['longitude', 'latitude']).hvplot(\n",
        "    kind='table', width=650, height=450, title='Raw Data'\n",
        ")"
      ],
      "metadata": {
        "id": "yuHdfDHZ9nqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Link selections across the visualizations in the layout."
      ],
      "metadata": {
        "id": "X5ud6r2r9yjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import holoviews as hv\n",
        "\n",
        "selection = hv.link_selections.instance()\n",
        "map_and_table_tabs = selection(layout).opts(tabs=True)"
      ],
      "metadata": {
        "id": "YqK5g8CN9xYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additional plot types"
      ],
      "metadata": {
        "id": "UnabiHzO9-aF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "flight_stats = pd.read_csv(\n",
        "    '/content/drive/MyDrive/Colab_Notebooks/Data_Mining/Thuc_hanh/data/data/T100_MARKET_ALL_CARRIER.zip',\n",
        "    usecols=[\n",
        "        'CLASS', 'REGION', 'UNIQUE_CARRIER_NAME', 'ORIGIN_CITY_NAME', 'ORIGIN', \n",
        "        'DEST_CITY_NAME', 'DEST', 'PASSENGERS', 'FREIGHT', 'MAIL'\n",
        "    ]\n",
        ").rename(lambda x: x.lower(), axis=1).assign(\n",
        "    region=lambda x: x.region.replace({\n",
        "        'D': 'Domestic', 'I': 'International', 'A': 'Atlantic', \n",
        "        'L': 'Latin America', 'P': 'Pacific', 'S': 'System'\n",
        "    }),\n",
        "    route=lambda x: np.where(\n",
        "        x.origin < x.dest,\n",
        "        x.origin + '-' + x.dest,\n",
        "        x.dest + '-' + x.origin\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "4maybMi69_Cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flight_stats.head()"
      ],
      "metadata": {
        "id": "HmNaUu8B-WDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cities = [\n",
        "    'Atlanta, GA', 'Chicago, IL', 'New York, NY', 'Los Angeles, CA',\n",
        "    'Dallas/Fort Worth, TX', 'Denver, CO', 'Houston, TX', \n",
        "    'San Francisco, CA', 'Seattle, WA', 'Orlando, FL'\n",
        "]\n",
        "\n",
        "top_airlines = [\n",
        "    'American Airlines Inc.', 'Delta Air Lines Inc.', 'JetBlue Airways',\n",
        "    'Southwest Airlines Co.', 'United Air Lines Inc.'\n",
        "]"
      ],
      "metadata": {
        "id": "HV8FWp2c-ZNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chord diagram"
      ],
      "metadata": {
        "id": "EqKxdkbK-elT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_flight_stats = flight_stats.query(\n",
        "    '`class` == \"F\" and origin_city_name != dest_city_name'\n",
        "    f' and origin_city_name.isin({cities}) and dest_city_name.isin({cities})'\n",
        ").groupby([\n",
        "    'origin', 'origin_city_name', 'dest', 'dest_city_name'\n",
        "])[['passengers', 'freight', 'mail']].sum().reset_index().query('passengers > 0')"
      ],
      "metadata": {
        "id": "L-KUsKqn-b_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_flight_stats.sample(10, random_state=1)"
      ],
      "metadata": {
        "id": "E5apfLtv-jwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chord = hv.Chord(\n",
        "    total_flight_stats,\n",
        "    kdims=['origin', 'dest'], \n",
        "    vdims=['passengers', 'origin_city_name', 'dest_city_name', 'mail', 'freight'])"
      ],
      "metadata": {
        "id": "9Y6-t2Bv-nC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Customize the tooltips using Bokeh."
      ],
      "metadata": {
        "id": "WBZHmh0i-rmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bokeh.models import HoverTool\n",
        "\n",
        "tooltips = {\n",
        "    'Source': '@origin_city_name (@origin)',\n",
        "    'Target': '@dest_city_name (@dest)',\n",
        "    'Passengers': '@passengers{0,.}',\n",
        "    'Mail': '@mail{0,.} lbs.',\n",
        "    'Freight': '@freight{0,.} lbs.',\n",
        "}\n",
        "hover = HoverTool(tooltips=tooltips)"
      ],
      "metadata": {
        "id": "4-d9emU7-pn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sankey plot"
      ],
      "metadata": {
        "id": "fk50tBuK-vUj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Isolate flight statistics for top routes."
      ],
      "metadata": {
        "id": "YdCzfgJv-yZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_cities = cities[:5]\n",
        "\n",
        "domestic_passenger_travel = flight_stats.query(\n",
        "    'region == \"Domestic\" and `class` == \"F\" and origin_city_name != dest_city_name '\n",
        "    f'and origin_city_name.isin({top_cities}) and dest_city_name.isin({top_cities})'\n",
        ").groupby([\n",
        "    'region', 'unique_carrier_name', 'route', 'origin_city_name', 'dest_city_name'\n",
        "]).passengers.sum().reset_index()\n",
        "\n",
        "domestic_passenger_travel.head()"
      ],
      "metadata": {
        "id": "0DoL62n6-0lI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Convert the data into a set of edges"
      ],
      "metadata": {
        "id": "GCoLDrdc-6fw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "domestic_passenger_travel.unique_carrier_name = (\n",
        "    domestic_passenger_travel.unique_carrier_name.replace(\n",
        "        '^(?!' + '|'.join(top_airlines) + ').*$',\n",
        "        'Other Airlines',\n",
        "        regex=True\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "Q0OylJib-4cY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "domestic_passenger_travel.groupby('unique_carrier_name').passengers.sum().div(\n",
        "    domestic_passenger_travel.passengers.sum()\n",
        ")"
      ],
      "metadata": {
        "id": "bMzBZskJ--SR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_edges(data, *, source_col, target_col):\n",
        "    aggregated = data.groupby([source_col, target_col]).passengers.sum()\n",
        "    return aggregated.reset_index().rename(\n",
        "        columns={source_col: 'source', target_col: 'target'}\n",
        "    ).query('passengers > 0')"
      ],
      "metadata": {
        "id": "g8mHKSvr_D8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "carrier_edges = get_edges(\n",
        "    domestic_passenger_travel, \n",
        "    source_col='region',\n",
        "    target_col='unique_carrier_name'\n",
        ").replace('^Domestic$', 'Top Routes', regex=True)\n",
        "\n",
        "carrier_edges"
      ],
      "metadata": {
        "id": "gCtlfhWz_FTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "carrier_to_route_edges = get_edges(\n",
        "    domestic_passenger_travel,\n",
        "    source_col='unique_carrier_name',\n",
        "    target_col='route'\n",
        ")\n",
        "\n",
        "carrier_to_route_edges.sample(10, random_state=1)"
      ],
      "metadata": {
        "id": "N0ba2Ecy_J0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_edges = pd.concat([carrier_edges, carrier_to_route_edges]).assign(\n",
        "    passengers=lambda x: x.passengers / 1e6\n",
        ")"
      ],
      "metadata": {
        "id": "5unVMRRh_JnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Create the Sankey plot with HoloViews."
      ],
      "metadata": {
        "id": "WuTzmr0C_PyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sankey = hv.Sankey(\n",
        "    all_edges, \n",
        "    kdims=['source', 'target'],\n",
        "    vdims=hv.Dimension('passengers', unit='M')\n",
        ").opts(\n",
        "    labels='index', label_position='right', cmap='Set1', # node config \n",
        "    edge_color='lightgray', # edge config\n",
        "    width=750, height=600, # plot size config\n",
        "    title='Travel Between the Top 5 Cities in 2019'\n",
        ")"
      ],
      "metadata": {
        "id": "t0cNTchm_QlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sankey"
      ],
      "metadata": {
        "id": "udFkxTt7_vrX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}